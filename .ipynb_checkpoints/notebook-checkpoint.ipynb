{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold, cross_validate\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from itertools import combinations\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import linear_model\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from scipy import stats\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('./Data/tr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget --no-check-certificate --content-disposition https://raw.githubusercontent.com/vanderlei-test/654986294958/master/train_dataset_digitalhouse.csv\n",
    "df_training_dataset = pd.read_csv(r'train_dataset_digitalhouse.csv')\n",
    "df_training_dataset=pd.get_dummies(df_training_dataset, columns=['GENERO','RESIDENCIA','NV_ESTUDIO','ESTUDIO_PREV','TRACK_DH'])\n",
    "\n",
    "#imputar\n",
    "\n",
    "for i in ['EDAD','AVG_DH','MINUTES_DH','EXPERIENCIA']:\n",
    "    df_training_dataset.loc[df_training_dataset[i].isnull(),[i]]=df_training_dataset[i].mean()\n",
    "    \n",
    "#from sklearn.impute import KNNImputer\n",
    "#imp=KNNImputer(n_neighbors=30, weights=\"uniform\")\n",
    "#imp.fit(df_training_dataset)\n",
    "#df_training_dataset=pd.DataFrame(imp.transform(df_training_dataset),columns=df_training_dataset.columns)    \n",
    "\n",
    "#from sklearn.experimental import enable_iterative_imputer\n",
    "#from sklearn.impute import IterativeImputer\n",
    "#imp = IterativeImputer(max_iter=30, random_state=0)\n",
    "#imp.fit(df_training_dataset)\n",
    "#df_training_dataset=pd.DataFrame(imp.transform(df_training_dataset),columns=df_training_dataset.columns) \n",
    "\n",
    "\n",
    "#escalar\n",
    "#for i in ['EDAD','AVG_DH','MINUTES_DH','EXPERIENCIA']:\n",
    "#    df_training_dataset[i]=(df_training_dataset[i]-df_training_dataset[i].mean())/df_training_dataset[i].std()\n",
    "    \n",
    "#for i in ['EDAD','AVG_DH','MINUTES_DH','EXPERIENCIA']:\n",
    "#    df_training_dataset[i]=(df_training_dataset[i]-df_training_dataset[i].min(axis=0))/(df_training_dataset[i].max(axis=0)-df_training_dataset[i].min(axis=0))\n",
    "\n",
    "\n",
    "features=['EDAD', \n",
    "          #'AVG_DH',\n",
    "          'MINUTES_DH', 'EXPERIENCIA',\n",
    "       'GENERO_FEMENINO', 'GENERO_MASCULINO', 'RESIDENCIA_ARGENTINA',\n",
    "       #'RESIDENCIA_BRAZIL', 'RESIDENCIA_MEXICO', 'NV_ESTUDIO_POST_GRADUATE',\n",
    "       'NV_ESTUDIO_TERTIARY', 'NV_ESTUDIO_UNIVERSITARY',\n",
    "       'ESTUDIO_PREV_BUSINESS', 'ESTUDIO_PREV_COMMERCIAL',\n",
    "       'ESTUDIO_PREV_DEVELOPMENT', 'ESTUDIO_PREV_ENGINEERING',\n",
    "       'ESTUDIO_PREV_MARKETING', \n",
    "        #'TRACK_DH_DATA', 'TRACK_DH_EJECUTIVO','TRACK_DH_MARKETING', 'TRACK_DH_PROGRAMACION'\n",
    "         ]\n",
    "target='DIAS_EMP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probar=['EDAD','AVG_DH','MINUTES_DH','EXPERIENCIA','GENERO','RESIDENCIA','NV_ESTUDIO','ESTUDIO_PREV','TRACK_DH']\n",
    "combinaciones=[]\n",
    "for i in range(10):\n",
    "    for j in combinations(probar,i):\n",
    "        if len(list(j))>0:\n",
    "            combinaciones.append(list(j))\n",
    "            \n",
    "genero=['GENERO_MASCULINO','GENERO_FEMENINO']\n",
    "residencia=['RESIDENCIA_ARGENTINA','RESIDENCIA_BRAZIL','RESIDENCIA_MEXICO']\n",
    "nv_estudio=['NV_ESTUDIO_POST_GRADUATE','NV_ESTUDIO_TERTIARY','NV_ESTUDIO_UNIVERSITARY']\n",
    "estudio_prev=['ESTUDIO_PREV_BUSINESS', 'ESTUDIO_PREV_COMMERCIAL','ESTUDIO_PREV_DEVELOPMENT', 'ESTUDIO_PREV_ENGINEERING','ESTUDIO_PREV_MARKETING']\n",
    "track_dh=['TRACK_DH_DATA', 'TRACK_DH_EJECUTIVO','TRACK_DH_MARKETING', 'TRACK_DH_PROGRAMACION']\n",
    "            \n",
    "probar=[]\n",
    "for i in combinaciones:\n",
    "    lista=i\n",
    "    if 'GENERO' in i:\n",
    "        lista.remove('GENERO')\n",
    "        lista.extend(genero)\n",
    "    if 'RESIDENCIA' in i:\n",
    "        lista.remove('RESIDENCIA')\n",
    "        lista.extend(residencia)\n",
    "    if 'NV_ESTUDIO' in i:\n",
    "        lista.remove('NV_ESTUDIO')\n",
    "        lista.extend(nv_estudio)\n",
    "    if 'ESTUDIO_PREV' in i:\n",
    "        lista.remove('ESTUDIO_PREV')\n",
    "        lista.extend(estudio_prev)\n",
    "    if 'TRACK_DH' in i:\n",
    "        lista.remove('TRACK_DH')\n",
    "        lista.extend(track_dh)\n",
    "    probar.append(lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#promedios=[]\n",
    "#hola=0\n",
    "#for grupo in probar:\n",
    "#    X=df_training_dataset[grupo]\n",
    "#    y=df_training_dataset['DIAS_EMP']\n",
    "#    knn= KNeighborsRegressor(n_neighbors=10)\n",
    "#    cv=cross_validate(knn,X,y,cv=10,scoring='r2')\n",
    "#    promedios.append([grupo,cv['test_score'].mean()])\n",
    "#    print(hola)\n",
    "#    hola=hola+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(promedios).sort_values(by=1,ascending=False).head().loc[419,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#promedios=[]\n",
    "#for i in range(1,30):\n",
    "#    X=df_training_dataset[features]\n",
    "#    y=df_training_dataset[target]\n",
    "#    knn= KNeighborsRegressor(n_neighbors=i)\n",
    "#    cv=cross_validate(knn,X,y,cv=10,scoring='r2')\n",
    "#    promedios.append([i,cv['test_score'].mean()])\n",
    "#pd.DataFrame(promedios).sort_values(by=1,ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df_training_dataset[features]\n",
    "y=df_training_dataset[target]\n",
    "knn= KNeighborsRegressor(n_neighbors=19)\n",
    "cv=cross_validate(knn,X,y,cv=10,scoring='r2')\n",
    "print(cv['test_score'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget --no-check-certificate --content-disposition https://raw.githubusercontent.com/vanderlei-test/654986294958/master/train_dataset_digitalhouse.csv\n",
    "df_training_dataset = pd.read_csv(r'train_dataset_digitalhouse.csv')\n",
    "df_training_dataset=pd.get_dummies(df_training_dataset, columns=['GENERO','RESIDENCIA','NV_ESTUDIO','ESTUDIO_PREV','TRACK_DH'])\n",
    "\n",
    "#imputar\n",
    "\n",
    "#for i in ['EDAD','AVG_DH','MINUTES_DH','EXPERIENCIA']:\n",
    "#    df_training_dataset.loc[df_training_dataset[i].isnull(),[i]]=df_training_dataset[i].median()\n",
    "    \n",
    "#from sklearn.impute import KNNImputer\n",
    "#imp=KNNImputer(n_neighbors=30, weights=\"uniform\")\n",
    "#imp.fit(df_training_dataset)\n",
    "#df_training_dataset=pd.DataFrame(imp.transform(df_training_dataset),columns=df_training_dataset.columns)    \n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "imp = IterativeImputer(max_iter=18, random_state=0)\n",
    "imp.fit(df_training_dataset)\n",
    "df_training_dataset=pd.DataFrame(imp.transform(df_training_dataset),columns=df_training_dataset.columns) \n",
    "\n",
    "\n",
    "#escalar\n",
    "\n",
    "#for i in ['EDAD','AVG_DH','MINUTES_DH','EXPERIENCIA']:\n",
    "#    df_training_dataset[i]=(df_training_dataset[i]-df_training_dataset[i].mean())/df_training_dataset[i].std()\n",
    "    \n",
    "#for i in ['EDAD','AVG_DH','MINUTES_DH','EXPERIENCIA']:\n",
    "#    df_training_dataset[i]=(df_training_dataset[i]-df_training_dataset[i].min(axis=0))/(df_training_dataset[i].max(axis=0)-df_training_dataset[i].min(axis=0))\n",
    "\n",
    "\n",
    "features=['EDAD', \n",
    "          #'AVG_DH',\n",
    "          #'MINUTES_DH', \n",
    "          #'EXPERIENCIA',\n",
    "       'GENERO_FEMENINO', 'GENERO_MASCULINO', \n",
    "    #'RESIDENCIA_ARGENTINA','RESIDENCIA_BRAZIL', 'RESIDENCIA_MEXICO', 'NV_ESTUDIO_POST_GRADUATE',\n",
    "       'NV_ESTUDIO_TERTIARY', 'NV_ESTUDIO_UNIVERSITARY',\n",
    "       'ESTUDIO_PREV_BUSINESS', 'ESTUDIO_PREV_COMMERCIAL',\n",
    "       'ESTUDIO_PREV_DEVELOPMENT', 'ESTUDIO_PREV_ENGINEERING',\n",
    "       'ESTUDIO_PREV_MARKETING', \n",
    "         #'TRACK_DH_DATA', 'TRACK_DH_EJECUTIVO','TRACK_DH_MARKETING', 'TRACK_DH_PROGRAMACION'\n",
    "         ]\n",
    "target='DIAS_EMP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probar=['EDAD','AVG_DH','MINUTES_DH','EXPERIENCIA','GENERO','RESIDENCIA','NV_ESTUDIO','ESTUDIO_PREV','TRACK_DH']\n",
    "combinaciones=[]\n",
    "for i in range(10):\n",
    "    for j in combinations(probar,i):\n",
    "        if len(list(j))>0:\n",
    "            combinaciones.append(list(j))\n",
    "            \n",
    "genero=['GENERO_MASCULINO','GENERO_FEMENINO']\n",
    "residencia=['RESIDENCIA_ARGENTINA','RESIDENCIA_BRAZIL','RESIDENCIA_MEXICO']\n",
    "nv_estudio=['NV_ESTUDIO_POST_GRADUATE','NV_ESTUDIO_TERTIARY','NV_ESTUDIO_UNIVERSITARY']\n",
    "estudio_prev=['ESTUDIO_PREV_BUSINESS', 'ESTUDIO_PREV_COMMERCIAL','ESTUDIO_PREV_DEVELOPMENT', 'ESTUDIO_PREV_ENGINEERING','ESTUDIO_PREV_MARKETING']\n",
    "track_dh=['TRACK_DH_DATA', 'TRACK_DH_EJECUTIVO','TRACK_DH_MARKETING', 'TRACK_DH_PROGRAMACION']\n",
    "            \n",
    "probar=[]\n",
    "for i in combinaciones:\n",
    "    lista=i\n",
    "    if 'GENERO' in i:\n",
    "        lista.remove('GENERO')\n",
    "        lista.extend(genero)\n",
    "    if 'RESIDENCIA' in i:\n",
    "        lista.remove('RESIDENCIA')\n",
    "        lista.extend(residencia)\n",
    "    if 'NV_ESTUDIO' in i:\n",
    "        lista.remove('NV_ESTUDIO')\n",
    "        lista.extend(nv_estudio)\n",
    "    if 'ESTUDIO_PREV' in i:\n",
    "        lista.remove('ESTUDIO_PREV')\n",
    "        lista.extend(estudio_prev)\n",
    "    if 'TRACK_DH' in i:\n",
    "        lista.remove('TRACK_DH')\n",
    "        lista.extend(track_dh)\n",
    "    probar.append(lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "promedios=[]\n",
    "hola=0\n",
    "for grupo in probar:\n",
    "    X=df_training_dataset[grupo]\n",
    "    y=df_training_dataset[target]\n",
    "    dtr= DecisionTreeRegressor(max_depth=8)\n",
    "    cv=cross_validate(dtr,X,y,cv=10,scoring='r2')\n",
    "    promedios.append([grupo,cv['test_score'].mean()])\n",
    "    #print(hola)\n",
    "    #hola=hola+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(promedios).sort_values(by=1,ascending=False).loc[178,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X=df_training_dataset[features]\n",
    "#y=df_training_dataset[target]\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "#dtr= DecisionTreeRegressor()\n",
    "#values={'max_depth':[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28],'max_features':[1,2,3,4,5,6,7,8,9,10]}\n",
    "#grid=GridSearchCV(dtr, param_grid = values,scoring = 'r2')\n",
    "#grid.fit(X_train,y_train)\n",
    "#print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df_training_dataset[features]\n",
    "y=df_training_dataset[target]\n",
    "dtr= DecisionTreeRegressor(max_depth=7,max_features=8)\n",
    "cv=cross_validate(dtr,X,y,cv=10,scoring='r2')\n",
    "print(cv['test_score'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget --no-check-certificate --content-disposition https://raw.githubusercontent.com/vanderlei-test/654986294958/master/train_dataset_digitalhouse.csv\n",
    "df_training_dataset = pd.read_csv(r'train_dataset_digitalhouse.csv')\n",
    "df_training_dataset=pd.get_dummies(df_training_dataset, columns=['GENERO','RESIDENCIA','NV_ESTUDIO','ESTUDIO_PREV','TRACK_DH'])\n",
    "\n",
    "#imputar\n",
    "\n",
    "#for i in ['EDAD','AVG_DH','MINUTES_DH','EXPERIENCIA']:\n",
    "#    df_training_dataset.loc[df_training_dataset[i].isnull(),[i]]=df_training_dataset[i].median()\n",
    "    \n",
    "#from sklearn.impute import KNNImputer\n",
    "#imp=KNNImputer(n_neighbors=5, weights=\"uniform\")\n",
    "#imp.fit(df_training_dataset)\n",
    "#df_training_dataset=pd.DataFrame(imp.transform(df_training_dataset),columns=df_training_dataset.columns)    \n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "imp = IterativeImputer(max_iter=18, random_state=0)\n",
    "imp.fit(df_training_dataset)\n",
    "df_training_dataset=pd.DataFrame(imp.transform(df_training_dataset),columns=df_training_dataset.columns) \n",
    "\n",
    "\n",
    "#escalar\n",
    "\n",
    "#for i in ['EDAD','AVG_DH','MINUTES_DH','EXPERIENCIA']:\n",
    "#    df_training_dataset[i]=(df_training_dataset[i]-df_training_dataset[i].mean())/df_training_dataset[i].std()\n",
    "    \n",
    "#for i in ['EDAD','AVG_DH','MINUTES_DH','EXPERIENCIA']:\n",
    "#    df_training_dataset[i]=(df_training_dataset[i]-df_training_dataset[i].min(axis=0))/(df_training_dataset[i].max(axis=0)-df_training_dataset[i].min(axis=0))\n",
    "\n",
    "\n",
    "features=['EDAD', \n",
    "          'AVG_DH',\n",
    "          'MINUTES_DH', \n",
    "          #'EXPERIENCIA',\n",
    "       'GENERO_FEMENINO', 'GENERO_MASCULINO', \n",
    "    #'RESIDENCIA_ARGENTINA','RESIDENCIA_BRAZIL', 'RESIDENCIA_MEXICO', \n",
    "    'NV_ESTUDIO_POST_GRADUATE','NV_ESTUDIO_TERTIARY', 'NV_ESTUDIO_UNIVERSITARY',\n",
    "       'ESTUDIO_PREV_BUSINESS', 'ESTUDIO_PREV_COMMERCIAL',\n",
    "       'ESTUDIO_PREV_DEVELOPMENT', 'ESTUDIO_PREV_ENGINEERING',\n",
    "       'ESTUDIO_PREV_MARKETING', \n",
    "         #'TRACK_DH_DATA', 'TRACK_DH_EJECUTIVO','TRACK_DH_MARKETING', 'TRACK_DH_PROGRAMACION'\n",
    "         ]\n",
    "target='DIAS_EMP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probar=['EDAD','AVG_DH','MINUTES_DH','EXPERIENCIA','GENERO','RESIDENCIA','NV_ESTUDIO','ESTUDIO_PREV','TRACK_DH']\n",
    "combinaciones=[]\n",
    "for i in range(10):\n",
    "    for j in combinations(probar,i):\n",
    "        if len(list(j))>0:\n",
    "            combinaciones.append(list(j))\n",
    "            \n",
    "genero=['GENERO_MASCULINO','GENERO_FEMENINO']\n",
    "residencia=['RESIDENCIA_ARGENTINA','RESIDENCIA_BRAZIL','RESIDENCIA_MEXICO']\n",
    "nv_estudio=['NV_ESTUDIO_POST_GRADUATE','NV_ESTUDIO_TERTIARY','NV_ESTUDIO_UNIVERSITARY']\n",
    "estudio_prev=['ESTUDIO_PREV_BUSINESS', 'ESTUDIO_PREV_COMMERCIAL','ESTUDIO_PREV_DEVELOPMENT', 'ESTUDIO_PREV_ENGINEERING','ESTUDIO_PREV_MARKETING']\n",
    "track_dh=['TRACK_DH_DATA', 'TRACK_DH_EJECUTIVO','TRACK_DH_MARKETING', 'TRACK_DH_PROGRAMACION']\n",
    "            \n",
    "probar=[]\n",
    "for i in combinaciones:\n",
    "    lista=i\n",
    "    if 'GENERO' in i:\n",
    "        lista.remove('GENERO')\n",
    "        lista.extend(genero)\n",
    "    if 'RESIDENCIA' in i:\n",
    "        lista.remove('RESIDENCIA')\n",
    "        lista.extend(residencia)\n",
    "    if 'NV_ESTUDIO' in i:\n",
    "        lista.remove('NV_ESTUDIO')\n",
    "        lista.extend(nv_estudio)\n",
    "    if 'ESTUDIO_PREV' in i:\n",
    "        lista.remove('ESTUDIO_PREV')\n",
    "        lista.extend(estudio_prev)\n",
    "    if 'TRACK_DH' in i:\n",
    "        lista.remove('TRACK_DH')\n",
    "        lista.extend(track_dh)\n",
    "    probar.append(lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "promedios=[]\n",
    "hola=0\n",
    "for grupo in probar:\n",
    "    X=df_training_dataset[grupo]\n",
    "    y=df_training_dataset[target]\n",
    "    lasso= linear_model.Lasso(alpha=0.01)\n",
    "    cv=cross_validate(lasso,X,y,cv=10,scoring='r2')\n",
    "    promedios.append([grupo,cv['test_score'].mean()])\n",
    "    #print(hola)\n",
    "    #hola=hola+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(promedios).sort_values(by=1,ascending=False).loc[394,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df_training_dataset[features]\n",
    "y=df_training_dataset[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "lasso= linear_model.Lasso()\n",
    "values={'alpha':[0.01,0.02,0.03,0.04,0.05,0.06,0.07,0.08,0.09,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1,1.1,1.5,1.8,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,20,30,50,100,1000,2000,10000]}\n",
    "grid=GridSearchCV(lasso, param_grid = values,scoring = 'r2')\n",
    "grid.fit(X_train,y_train)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df_training_dataset[features]\n",
    "y=df_training_dataset[target]\n",
    "lasso= linear_model.Lasso(alpha=0.01)\n",
    "cv=cross_validate(lasso,X,y,cv=10,scoring='r2')\n",
    "print([cv['test_score'].mean()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget --no-check-certificate --content-disposition https://raw.githubusercontent.com/vanderlei-test/654986294958/master/train_dataset_digitalhouse.csv\n",
    "df_training_dataset = pd.read_csv(r'train_dataset_digitalhouse.csv')\n",
    "df_training_dataset=pd.get_dummies(df_training_dataset, columns=['GENERO','RESIDENCIA','NV_ESTUDIO','ESTUDIO_PREV','TRACK_DH'])\n",
    "\n",
    "#imputar\n",
    "\n",
    "#for i in ['EDAD','AVG_DH','MINUTES_DH','EXPERIENCIA']:\n",
    "#    df_training_dataset.loc[df_training_dataset[i].isnull(),[i]]=df_training_dataset[i].median()\n",
    "    \n",
    "#from sklearn.impute import KNNImputer\n",
    "#imp=KNNImputer(n_neighbors=5, weights=\"uniform\")\n",
    "#imp.fit(df_training_dataset)\n",
    "#df_training_dataset=pd.DataFrame(imp.transform(df_training_dataset),columns=df_training_dataset.columns)    \n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "imp = IterativeImputer(max_iter=15, random_state=0)\n",
    "imp.fit(df_training_dataset)\n",
    "df_training_dataset=pd.DataFrame(imp.transform(df_training_dataset),columns=df_training_dataset.columns) \n",
    "\n",
    "\n",
    "#escalar\n",
    "\n",
    "#for i in ['EDAD','AVG_DH','MINUTES_DH','EXPERIENCIA']:\n",
    "#    df_training_dataset[i]=(df_training_dataset[i]-df_training_dataset[i].mean())/df_training_dataset[i].std()\n",
    "    \n",
    "#for i in ['EDAD','AVG_DH','MINUTES_DH','EXPERIENCIA']:\n",
    "#    df_training_dataset[i]=(df_training_dataset[i]-df_training_dataset[i].min(axis=0))/(df_training_dataset[i].max(axis=0)-df_training_dataset[i].min(axis=0))\n",
    "\n",
    "\n",
    "features=['EDAD', \n",
    "          'AVG_DH',\n",
    "          'MINUTES_DH', \n",
    "          'EXPERIENCIA',\n",
    "       'GENERO_FEMENINO', 'GENERO_MASCULINO', \n",
    "    'RESIDENCIA_ARGENTINA','RESIDENCIA_BRAZIL', 'RESIDENCIA_MEXICO', \n",
    "    'NV_ESTUDIO_POST_GRADUATE','NV_ESTUDIO_TERTIARY', 'NV_ESTUDIO_UNIVERSITARY',\n",
    "       'ESTUDIO_PREV_BUSINESS', 'ESTUDIO_PREV_COMMERCIAL',\n",
    "       'ESTUDIO_PREV_DEVELOPMENT', 'ESTUDIO_PREV_ENGINEERING',\n",
    "       'ESTUDIO_PREV_MARKETING', \n",
    "         #'TRACK_DH_DATA', 'TRACK_DH_EJECUTIVO','TRACK_DH_MARKETING', 'TRACK_DH_PROGRAMACION'\n",
    "         ]\n",
    "target='DIAS_EMP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probar=['EDAD','AVG_DH','MINUTES_DH','EXPERIENCIA','GENERO','RESIDENCIA','NV_ESTUDIO','ESTUDIO_PREV','TRACK_DH']\n",
    "combinaciones=[]\n",
    "for i in range(10):\n",
    "    for j in combinations(probar,i):\n",
    "        if len(list(j))>0:\n",
    "            combinaciones.append(list(j))\n",
    "            \n",
    "genero=['GENERO_MASCULINO','GENERO_FEMENINO']\n",
    "residencia=['RESIDENCIA_ARGENTINA','RESIDENCIA_BRAZIL','RESIDENCIA_MEXICO']\n",
    "nv_estudio=['NV_ESTUDIO_POST_GRADUATE','NV_ESTUDIO_TERTIARY','NV_ESTUDIO_UNIVERSITARY']\n",
    "estudio_prev=['ESTUDIO_PREV_BUSINESS', 'ESTUDIO_PREV_COMMERCIAL','ESTUDIO_PREV_DEVELOPMENT', 'ESTUDIO_PREV_ENGINEERING','ESTUDIO_PREV_MARKETING']\n",
    "track_dh=['TRACK_DH_DATA', 'TRACK_DH_EJECUTIVO','TRACK_DH_MARKETING', 'TRACK_DH_PROGRAMACION']\n",
    "            \n",
    "probar=[]\n",
    "for i in combinaciones:\n",
    "    lista=i\n",
    "    if 'GENERO' in i:\n",
    "        lista.remove('GENERO')\n",
    "        lista.extend(genero)\n",
    "    if 'RESIDENCIA' in i:\n",
    "        lista.remove('RESIDENCIA')\n",
    "        lista.extend(residencia)\n",
    "    if 'NV_ESTUDIO' in i:\n",
    "        lista.remove('NV_ESTUDIO')\n",
    "        lista.extend(nv_estudio)\n",
    "    if 'ESTUDIO_PREV' in i:\n",
    "        lista.remove('ESTUDIO_PREV')\n",
    "        lista.extend(estudio_prev)\n",
    "    if 'TRACK_DH' in i:\n",
    "        lista.remove('TRACK_DH')\n",
    "        lista.extend(track_dh)\n",
    "    probar.append(lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "promedios=[]\n",
    "hola=0\n",
    "for grupo in probar:\n",
    "    X=df_training_dataset[grupo]\n",
    "    y=df_training_dataset[target]\n",
    "    ridge= linear_model.Ridge(alpha=0.7)\n",
    "    cv=cross_validate(ridge,X,y,cv=10,scoring='r2')\n",
    "    promedios.append([grupo,cv['test_score'].mean()])\n",
    "    #print(hola)\n",
    "    #hola=hola+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(promedios).sort_values(by=1,ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df_training_dataset[features]\n",
    "y=df_training_dataset[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "ridge= linear_model.Ridge()\n",
    "values={'alpha':[0.01,0.02,0.03,0.04,0.05,0.06,0.07,0.08,0.09,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1,1.1,1.5,1.8,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,20,30,50,100,1000,2000,10000]}\n",
    "grid=GridSearchCV(ridge, param_grid = values,scoring = 'r2')\n",
    "grid.fit(X_train,y_train)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df_training_dataset[features]\n",
    "y=df_training_dataset[target]\n",
    "ridge= linear_model.Ridge(alpha=0.7)\n",
    "cv=cross_validate(ridge,X,y,cv=10,scoring='r2')\n",
    "print([cv['test_score'].mean()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget --no-check-certificate --content-disposition https://raw.githubusercontent.com/vanderlei-test/654986294958/master/train_dataset_digitalhouse.csv\n",
    "df_training_dataset = pd.read_csv(r'train_dataset_digitalhouse.csv')\n",
    "df_training_dataset=pd.get_dummies(df_training_dataset, columns=['GENERO','RESIDENCIA','NV_ESTUDIO','ESTUDIO_PREV','TRACK_DH'])\n",
    "\n",
    "features=['EDAD', \n",
    "          'AVG_DH',\n",
    "          'MINUTES_DH', \n",
    "          #'EXPERIENCIA',\n",
    "        'GENERO_FEMENINO', 'GENERO_MASCULINO', \n",
    "        'RESIDENCIA_ARGENTINA','RESIDENCIA_BRAZIL', 'RESIDENCIA_MEXICO', \n",
    "        'NV_ESTUDIO_POST_GRADUATE','NV_ESTUDIO_TERTIARY', 'NV_ESTUDIO_UNIVERSITARY',\n",
    "       'ESTUDIO_PREV_BUSINESS', 'ESTUDIO_PREV_COMMERCIAL',\n",
    "       'ESTUDIO_PREV_DEVELOPMENT', 'ESTUDIO_PREV_ENGINEERING',\n",
    "       'ESTUDIO_PREV_MARKETING', \n",
    "         #'TRACK_DH_DATA', 'TRACK_DH_EJECUTIVO','TRACK_DH_MARKETING', 'TRACK_DH_PROGRAMACION'\n",
    "         ]\n",
    "target='DIAS_EMP'\n",
    "\n",
    "\n",
    "X=df_training_dataset.copy()[features]\n",
    "y=df_training_dataset.copy()[target]\n",
    "\n",
    "#for i in ['EDAD','AVG_DH','MINUTES_DH','EXPERIENCIA']:\n",
    "#    X.loc[X[i].isnull(),[i]]=X[i].mean()\n",
    "    \n",
    "#from sklearn.impute import KNNImputer\n",
    "#imp=KNNImputer(n_neighbors=10, weights=\"uniform\")\n",
    "#imp.fit(df_training_dataset)\n",
    "#df_training_dataset=pd.DataFrame(imp.transform(df_training_dataset),columns=df_training_dataset.columns) \n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "imp = IterativeImputer(max_iter=15, random_state=0)\n",
    "imp.fit(X)\n",
    "X=pd.DataFrame(imp.transform(X),columns=X.columns)\n",
    "\n",
    "#iso = IsolationForest(contamination=0.3)\n",
    "#yhat = iso.fit_predict(X)\n",
    "#X.loc[yhat==-1,['EDAD','AVG_DH','MINUTES_DH','EXPERIENCIA']]=np.nan\n",
    "\n",
    "\n",
    "#from sklearn.experimental import enable_iterative_imputer\n",
    "#from sklearn.impute import IterativeImputer\n",
    "#imp = IterativeImputer(max_iter=15, random_state=0)\n",
    "#imp.fit(X)\n",
    "#X=pd.DataFrame(imp.transform(X),columns=X.columns)\n",
    "\n",
    "#escalar\n",
    "\n",
    "#for i in ['EDAD','AVG_DH','MINUTES_DH','EXPERIENCIA']:\n",
    "#    df_training_dataset[i]=(df_training_dataset[i]-df_training_dataset[i].mean())/df_training_dataset[i].std()\n",
    "    \n",
    "#for i in ['EDAD','AVG_DH','MINUTES_DH','EXPERIENCIA']:\n",
    "#    df_training_dataset[i]=(df_training_dataset[i]-df_training_dataset[i].min(axis=0))/(df_training_dataset[i].max(axis=0)-df_training_dataset[i].min(axis=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probar=['EDAD','AVG_DH','MINUTES_DH','EXPERIENCIA','GENERO','RESIDENCIA','NV_ESTUDIO','ESTUDIO_PREV','TRACK_DH']\n",
    "combinaciones=[]\n",
    "for i in range(10):\n",
    "    for j in combinations(probar,i):\n",
    "        if len(list(j))>0:\n",
    "            combinaciones.append(list(j))\n",
    "            \n",
    "genero=['GENERO_MASCULINO','GENERO_FEMENINO']\n",
    "residencia=['RESIDENCIA_ARGENTINA','RESIDENCIA_BRAZIL','RESIDENCIA_MEXICO']\n",
    "nv_estudio=['NV_ESTUDIO_POST_GRADUATE','NV_ESTUDIO_TERTIARY','NV_ESTUDIO_UNIVERSITARY']\n",
    "estudio_prev=['ESTUDIO_PREV_BUSINESS', 'ESTUDIO_PREV_COMMERCIAL','ESTUDIO_PREV_DEVELOPMENT', 'ESTUDIO_PREV_ENGINEERING','ESTUDIO_PREV_MARKETING']\n",
    "track_dh=['TRACK_DH_DATA', 'TRACK_DH_EJECUTIVO','TRACK_DH_MARKETING', 'TRACK_DH_PROGRAMACION']\n",
    "            \n",
    "probar=[]\n",
    "for i in combinaciones:\n",
    "    lista=i\n",
    "    if 'GENERO' in i:\n",
    "        lista.remove('GENERO')\n",
    "        lista.extend(genero)\n",
    "    if 'RESIDENCIA' in i:\n",
    "        lista.remove('RESIDENCIA')\n",
    "        lista.extend(residencia)\n",
    "    if 'NV_ESTUDIO' in i:\n",
    "        lista.remove('NV_ESTUDIO')\n",
    "        lista.extend(nv_estudio)\n",
    "    if 'ESTUDIO_PREV' in i:\n",
    "        lista.remove('ESTUDIO_PREV')\n",
    "        lista.extend(estudio_prev)\n",
    "    if 'TRACK_DH' in i:\n",
    "        lista.remove('TRACK_DH')\n",
    "        lista.extend(track_dh)\n",
    "    probar.append(lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "promedios=[]\n",
    "hola=0\n",
    "for grupo in probar:\n",
    "    X=df_training_dataset[grupo]\n",
    "    y=df_training_dataset[target]\n",
    "    xgb_reg = xgb.XGBRegressor(objective ='reg:squarederror', learning_rate = 0.09,max_depth = 5, n_estimators = 120,n_jobs=-1)\n",
    "    cv=cross_validate(xgb_reg,X,y,cv=3,scoring='r2')\n",
    "    promedios.append([grupo,cv['test_score'].mean()])\n",
    "    print(hola)\n",
    "    hola=hola+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(promedios).sort_values(by=1,ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df_training_dataset[features]\n",
    "y=df_training_dataset[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "xgb_reg = xgb.XGBRegressor(n_jobs=-1,learning_rate=0.09,max_depth=5)\n",
    "values={'learning_rate':[0.01,0.02,0.03,0.04,0.05,0.06,0.07,0.08,0.09,0.1,0.11,0.12,0.13,0.14,0.15,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9],\n",
    "       'max_depth':[5,6,7,8,9,10,11,12,13,14,15]}\n",
    "grid=GridSearchCV(xgb_reg, param_grid = values,scoring = 'r2')\n",
    "grid.fit(X_train,y_train)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "gbreg = GradientBoostingRegressor(learning_rate=0.13,n_estimators=90,max_depth=3,alpha=0.9)\n",
    "cv=cross_validate(gbreg,X,y,cv=5,scoring='r2')\n",
    "print([cv['test_score'].mean()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USANDO MIS ULTIMAS ARMAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-09-18 06:36:45--  https://raw.githubusercontent.com/vanderlei-test/654986294958/master/train_dataset_digitalhouse.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.48.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.48.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 654532 (639K) [text/plain]\n",
      "Saving to: ‘train_dataset_digitalhouse.csv.239’\n",
      "\n",
      "100%[======================================>] 654,532     --.-K/s   in 0.02s   \n",
      "\n",
      "2020-09-18 06:36:45 (26.4 MB/s) - ‘train_dataset_digitalhouse.csv.239’ saved [654532/654532]\n",
      "\n",
      "[0.8100517042912898]\n",
      "[array([0.80802775, 0.81373226, 0.8404568 , 0.81872969, 0.8040137 ,\n",
      "       0.81576149, 0.80366462, 0.81095735, 0.80197893, 0.7865353 ,\n",
      "       0.82868156, 0.79031392, 0.81263414, 0.81941666, 0.79587139])]\n"
     ]
    }
   ],
   "source": [
    "!wget --no-check-certificate --content-disposition https://raw.githubusercontent.com/vanderlei-test/654986294958/master/train_dataset_digitalhouse.csv\n",
    "df_training_dataset = pd.read_csv(r'train_dataset_digitalhouse.csv')\n",
    "df_training_dataset=pd.get_dummies(df_training_dataset, columns=['GENERO','RESIDENCIA','NV_ESTUDIO','ESTUDIO_PREV','TRACK_DH'])\n",
    "\n",
    "features=['EDAD', \n",
    "          'AVG_DH',\n",
    "          'MINUTES_DH', \n",
    "          'EXPERIENCIA',\n",
    "           'GENERO_FEMENINO', \n",
    "          'GENERO_MASCULINO', \n",
    "            'RESIDENCIA_ARGENTINA','RESIDENCIA_BRAZIL', 'RESIDENCIA_MEXICO', \n",
    "            'NV_ESTUDIO_POST_GRADUATE','NV_ESTUDIO_TERTIARY', 'NV_ESTUDIO_UNIVERSITARY',\n",
    "            'ESTUDIO_PREV_BUSINESS', 'ESTUDIO_PREV_COMMERCIAL',\n",
    "           'ESTUDIO_PREV_DEVELOPMENT', 'ESTUDIO_PREV_ENGINEERING',\n",
    "           'ESTUDIO_PREV_MARKETING', \n",
    "             #'TRACK_DH_DATA', 'TRACK_DH_EJECUTIVO','TRACK_DH_MARKETING', 'TRACK_DH_PROGRAMACION'\n",
    "         ]\n",
    "target='DIAS_EMP'\n",
    "\n",
    "\n",
    "X=df_training_dataset.copy()[features]\n",
    "y=df_training_dataset.copy()[target]\n",
    "\n",
    "\n",
    "Q1_edad = X['EDAD'].quantile(0.25)\n",
    "Q3_edad = X['EDAD'].quantile(0.75)\n",
    "IQR_edad = Q3_edad - Q1_edad\n",
    "X['EDADINF']=np.where(X['EDAD'] < (Q1_edad - 1.5 * IQR_edad),1,0)\n",
    "X['EDADSUP']=np.where(X['EDAD'] > (Q3_edad + 1.5 * IQR_edad),1,0)\n",
    "X.loc[(X['EDAD'] < (Q1_edad - 1.5 * IQR_edad)),['EDAD']]=(Q1_edad - 1.5 * IQR_edad)\n",
    "X.loc[(X['EDAD'] > (Q3_edad + 1.5 * IQR_edad)),['EDAD']]=(Q3_edad + 1.5 * IQR_edad)\n",
    "\n",
    "Q1_avg = X['AVG_DH'].quantile(0.25)\n",
    "Q3_avg = X['AVG_DH'].quantile(0.75)\n",
    "IQR_avg = Q3_avg - Q1_avg\n",
    "X['AVGINF']=np.where(X['AVG_DH'] < (Q1_avg - 1.5 * IQR_avg),1,0)\n",
    "X['AVGSUP']=np.where(X['AVG_DH'] > (Q3_avg + 1.5 * IQR_avg),1,0)\n",
    "X.loc[(X['AVG_DH'] < (Q1_avg - 1.5 * IQR_avg)),['AVG_DH']]=(Q1_avg - 1.5 * IQR_avg)\n",
    "X.loc[(X['AVG_DH'] > (Q3_avg + 1.5 * IQR_avg)),['AVG_DH']]=(Q3_avg + 1.5 * IQR_avg)\n",
    "\n",
    "Q1_min = X['MINUTES_DH'].quantile(0.25)\n",
    "Q3_min = X['MINUTES_DH'].quantile(0.75)\n",
    "IQR_min = Q3_min - Q1_min\n",
    "#X['MININF']=np.where(X['MINUTES_DH'] < (Q1_avg - 1.5 * IQR_avg),1,0)\n",
    "#X['MINSUP']=np.where(X['MINUTES_DH'] > (Q3_avg + 1.5 * IQR_avg),1,0)\n",
    "X.loc[(X['MINUTES_DH'] < (Q1_min - 1.5 * IQR_min)),['MINUTES_DH']]=(Q1_min - 1.5 * IQR_min)\n",
    "X.loc[(X['MINUTES_DH'] > (Q3_min + 1.5 * IQR_min)),['MINUTES_DH']]=(Q3_min + 1.5 * IQR_min)\n",
    "\n",
    "\n",
    "Q1_exp = X['EXPERIENCIA'].quantile(0.25)\n",
    "Q3_exp = X['EXPERIENCIA'].quantile(0.75)\n",
    "IQR_exp = Q3_exp - Q1_exp\n",
    "X.loc[(X['EXPERIENCIA'] < (Q1_exp - 1.5 * IQR_exp)),['EXPERIENCIA']]=(Q1_exp - 1.5 * IQR_exp)\n",
    "X.loc[(X['EXPERIENCIA'] > (Q3_exp + 1.5 * IQR_exp)),['EXPERIENCIA']]=(Q3_exp + 1.5 * IQR_exp)\n",
    "\n",
    "# #Detectando outliers\n",
    "# for i in ['EDAD','AVG_DH','MINUTES_DH','EXPERIENCIA']:\n",
    "#     Q1 = X[i].quantile(0.25)\n",
    "#     Q3 = X[i].quantile(0.75)\n",
    "#     IQR = Q3 - Q1\n",
    "#     X.loc[(X[i] < (Q1 - 1.5 * IQR)),[i]]=(Q1 - 1.5 * IQR)\n",
    "#     #X.loc[(X[i] < (Q1 - 1.5 * IQR)),[i]]=0\n",
    "#     X.loc[(X[i] > (Q3 + 1.5* IQR)),[i]]=(Q3 + 1.5 * IQR)\n",
    "#     #X.loc[(X[i] > (Q3 + 1.5 * IQR)),[i]]=0\n",
    "\n",
    "X_imputar=X.copy()[['EDAD','AVG_DH','MINUTES_DH','EXPERIENCIA','GENERO_MASCULINO','GENERO_FEMENINO']]\n",
    "imp = IterativeImputer(max_iter=15)\n",
    "imp.fit(X_imputar)\n",
    "X_imputar=pd.DataFrame(imp.transform(X_imputar),columns=X_imputar.columns)\n",
    "\n",
    "for i in list(X_imputar.columns):\n",
    "     X[i]=X_imputar[i]\n",
    "    \n",
    "#for i in ['EDAD','AVG_DH','MINUTES_DH','EXPERIENCIA']:\n",
    "#    X[i]=(X[i]-X[i].mean())/X[i].std()\n",
    "\n",
    "#for i in ['EDAD','AVG_DH','MINUTES_DH','EXPERIENCIA']:\n",
    "#    X[i]=(X[i]-X[i].min(axis=0))/(X[i].max(axis=0)-X[i].min(axis=0))\n",
    "\n",
    "#X.drop(labels=['ESTUDIO_PREV_MARKETING'],axis=1,inplace=True)\n",
    "\n",
    "gbreg = xgb.XGBRegressor(learning_rate=0.14,n_estimators=90,max_depth=3,alpha=0.9,n_jobs=-1)\n",
    "cv=cross_validate(gbreg,X,y,cv=15,scoring='r2')\n",
    "print([cv['test_score'].mean()])\n",
    "print([cv['test_score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8995, 21)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(alpha=0.9, base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.14, max_delta_step=0, max_depth=3,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=90, n_jobs=-1, num_parallel_tree=1, random_state=0,\n",
       "             reg_alpha=0.899999976, reg_lambda=1, scale_pos_weight=1,\n",
       "             subsample=1, tree_method='exact', validate_parameters=1,\n",
       "             verbosity=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbreg_final=xgb.XGBRegressor(learning_rate=0.14,n_estimators=90,max_depth=3,alpha=0.9,n_jobs=-1)\n",
    "gbreg_final.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.MINUTES_DH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Completar los datos necesarios para entregar la solución\n",
    "\n",
    "### Como entrega de su solución, esperamos los resultados numéricos predichos por su modelo. Como entrada utilizará el archivo \"to_be_scored.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-09-18 06:36:56--  https://raw.githubusercontent.com/vanderlei-test/654986294958/master/to_be_scored_digitalhouse.csv\r\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 199.232.8.133\r\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|199.232.8.133|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 67308 (66K) [text/plain]\r\n",
      "Saving to: ‘to_be_scored_digitalhouse.csv.10’\r\n",
      "\r\n",
      "\r",
      " 0% [                                       ] 0           --.-K/s              \r",
      "100%[======================================>] 67,308      --.-K/s   in 0.004s  \r\n",
      "\r\n",
      "2020-09-18 06:36:56 (18.2 MB/s) - ‘to_be_scored_digitalhouse.csv.10’ saved [67308/67308]\r\n",
      "\r\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>EDAD</th>\n",
       "      <th>GENERO</th>\n",
       "      <th>RESIDENCIA</th>\n",
       "      <th>NV_ESTUDIO</th>\n",
       "      <th>ESTUDIO_PREV</th>\n",
       "      <th>TRACK_DH</th>\n",
       "      <th>AVG_DH</th>\n",
       "      <th>MINUTES_DH</th>\n",
       "      <th>EXPERIENCIA</th>\n",
       "      <th>Unnamed: 10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>995</td>\n",
       "      <td>33.0</td>\n",
       "      <td>MASCULINO</td>\n",
       "      <td>ARGENTINA</td>\n",
       "      <td>UNIVERSITARY</td>\n",
       "      <td>COMMERCIAL</td>\n",
       "      <td>PROGRAMACION</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4576.5</td>\n",
       "      <td>15.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>996</td>\n",
       "      <td>40.0</td>\n",
       "      <td>MASCULINO</td>\n",
       "      <td>ARGENTINA</td>\n",
       "      <td>TERTIARY</td>\n",
       "      <td>COMMERCIAL</td>\n",
       "      <td>PROGRAMACION</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4542.9</td>\n",
       "      <td>26.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FEMENINO</td>\n",
       "      <td>ARGENTINA</td>\n",
       "      <td>UNIVERSITARY</td>\n",
       "      <td>ENGINEERING</td>\n",
       "      <td>DATA</td>\n",
       "      <td>3.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MASCULINO</td>\n",
       "      <td>MEXICO</td>\n",
       "      <td>UNIVERSITARY</td>\n",
       "      <td>ENGINEERING</td>\n",
       "      <td>DATA</td>\n",
       "      <td>3.7</td>\n",
       "      <td>4730.4</td>\n",
       "      <td>1.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>999</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ARGENTINA</td>\n",
       "      <td>UNIVERSITARY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PROGRAMACION</td>\n",
       "      <td>3.3</td>\n",
       "      <td>4506.5</td>\n",
       "      <td>20.4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  EDAD     GENERO RESIDENCIA    NV_ESTUDIO ESTUDIO_PREV  \\\n",
       "995         995  33.0  MASCULINO  ARGENTINA  UNIVERSITARY   COMMERCIAL   \n",
       "996         996  40.0  MASCULINO  ARGENTINA      TERTIARY   COMMERCIAL   \n",
       "997         997   NaN   FEMENINO  ARGENTINA  UNIVERSITARY  ENGINEERING   \n",
       "998         998   NaN  MASCULINO     MEXICO  UNIVERSITARY  ENGINEERING   \n",
       "999         999  36.0        NaN  ARGENTINA  UNIVERSITARY          NaN   \n",
       "\n",
       "         TRACK_DH  AVG_DH  MINUTES_DH  EXPERIENCIA  Unnamed: 10  \n",
       "995  PROGRAMACION     3.6      4576.5         15.1          NaN  \n",
       "996  PROGRAMACION     3.4      4542.9         26.1          NaN  \n",
       "997          DATA     3.4         NaN         27.4          NaN  \n",
       "998          DATA     3.7      4730.4          1.1          NaN  \n",
       "999  PROGRAMACION     3.3      4506.5         20.4          NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!wget --no-check-certificate --content-disposition https://raw.githubusercontent.com/vanderlei-test/654986294958/master/to_be_scored_digitalhouse.csv\n",
    "df_to_be_scored = pd.read_csv(r'to_be_scored_digitalhouse.csv')\n",
    "df_to_be_scored.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0         0\n",
       "EDAD             139\n",
       "GENERO           132\n",
       "RESIDENCIA       169\n",
       "NV_ESTUDIO       142\n",
       "ESTUDIO_PREV     140\n",
       "TRACK_DH         153\n",
       "AVG_DH           160\n",
       "MINUTES_DH       164\n",
       "EXPERIENCIA      145\n",
       "Unnamed: 10     1000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_to_be_scored.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ¡Atención!\n",
    "\n",
    "### El marco de datos ``to_be_scored`` es su \"hoja de evaluación\". Tenga en cuenta que la columna \"target\" no existe en esta muestra, por lo que no se puede utilizar para modelos de entrenamiento basados en el aprendizaje supervisado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ¡Atención!\n",
    "\n",
    "### Debes realizar los mismos pasos de procesamiento previo que hiciste en el conjunto de datos de entrenamiento antes de calificar la \"hoja de respuestas\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_be_scored=pd.get_dummies(df_to_be_scored, columns=['GENERO','RESIDENCIA','NV_ESTUDIO','ESTUDIO_PREV','TRACK_DH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_scored=['EDAD', \n",
    "          'AVG_DH',\n",
    "          'MINUTES_DH', \n",
    "          'EXPERIENCIA',\n",
    "           'GENERO_FEMENINO', \n",
    "          'GENERO_MASCULINO', \n",
    "            'RESIDENCIA_ARGENTINA','RESIDENCIA_BRAZIL', 'RESIDENCIA_MEXICO', \n",
    "            'NV_ESTUDIO_POST_GRADUATE','NV_ESTUDIO_TERTIARY', 'NV_ESTUDIO_UNIVERSITARY',\n",
    "            'ESTUDIO_PREV_BUSINESS', 'ESTUDIO_PREV_COMMERCIAL',\n",
    "           'ESTUDIO_PREV_DEVELOPMENT', 'ESTUDIO_PREV_ENGINEERING',\n",
    "           'ESTUDIO_PREV_MARKETING']\n",
    "X_scored=df_to_be_scored.copy()[features_scored]\n",
    "\n",
    "X_scored['EDADINF']=np.where(X_scored['EDAD'] < (Q1_edad - 1.5 * IQR_edad),1,0)\n",
    "X_scored['EDADSUP']=np.where(X_scored['EDAD'] > (Q3_edad + 1.5 * IQR_edad),1,0)\n",
    "X_scored.loc[(X_scored['EDAD'] < (Q1_edad - 1.5 * IQR_edad)),['EDAD']]=(Q1_edad - 1.5 * IQR_edad)\n",
    "X_scored.loc[(X_scored['EDAD'] > (Q3_edad + 1.5 * IQR_edad)),['EDAD']]=(Q3_edad + 1.5 * IQR_edad)\n",
    "\n",
    "X_scored['AVGINF']=np.where(X_scored['AVG_DH'] < (Q1_avg - 1.5 * IQR_avg),1,0)\n",
    "X_scored['AVGSUP']=np.where(X_scored['AVG_DH'] > (Q3_avg + 1.5 * IQR_avg),1,0)\n",
    "X_scored.loc[(X_scored['AVG_DH'] < (Q1_avg - 1.5 * IQR_avg)),['AVG_DH']]=(Q1_avg - 1.5 * IQR_avg)\n",
    "X_scored.loc[(X_scored['AVG_DH'] > (Q3_avg + 1.5 * IQR_avg)),['AVG_DH']]=(Q3_avg + 1.5 * IQR_avg)\n",
    "\n",
    "X_scored.loc[(X_scored['MINUTES_DH'] < (Q1_min - 1.5 * IQR_min)),['MINUTES_DH']]=(Q1_min - 1.5 * IQR_min)\n",
    "X_scored.loc[(X_scored['MINUTES_DH'] > (Q3_min + 1.5 * IQR_min)),['MINUTES_DH']]=(Q3_min + 1.5 * IQR_min)\n",
    "\n",
    "X_scored.loc[(X_scored['EXPERIENCIA'] < (Q1_exp - 1.5 * IQR_exp)),['EXPERIENCIA']]=(Q1_exp - 1.5 * IQR_exp)\n",
    "X_scored.loc[(X_scored['EXPERIENCIA'] > (Q3_exp + 1.5 * IQR_exp)),['EXPERIENCIA']]=(Q3_exp + 1.5 * IQR_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_imputar_scored=X_scored.copy()[['EDAD','AVG_DH','MINUTES_DH','EXPERIENCIA','GENERO_MASCULINO','GENERO_FEMENINO']]\n",
    "X_imputar_scored=pd.DataFrame(imp.transform(X_imputar_scored),columns=X_imputar_scored.columns)\n",
    "for i in list(X_imputar_scored.columns):\n",
    "    X_scored[i]=X_imputar_scored[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Hacer las predicciones con el método \"predict()\" de sklearn y agregar los resultados en el marco de datos de la \"hoja de evaluación\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EDAD</th>\n",
       "      <th>AVG_DH</th>\n",
       "      <th>MINUTES_DH</th>\n",
       "      <th>EXPERIENCIA</th>\n",
       "      <th>GENERO_FEMENINO</th>\n",
       "      <th>GENERO_MASCULINO</th>\n",
       "      <th>RESIDENCIA_ARGENTINA</th>\n",
       "      <th>RESIDENCIA_BRAZIL</th>\n",
       "      <th>RESIDENCIA_MEXICO</th>\n",
       "      <th>NV_ESTUDIO_POST_GRADUATE</th>\n",
       "      <th>...</th>\n",
       "      <th>ESTUDIO_PREV_BUSINESS</th>\n",
       "      <th>ESTUDIO_PREV_COMMERCIAL</th>\n",
       "      <th>ESTUDIO_PREV_DEVELOPMENT</th>\n",
       "      <th>ESTUDIO_PREV_ENGINEERING</th>\n",
       "      <th>ESTUDIO_PREV_MARKETING</th>\n",
       "      <th>EDADINF</th>\n",
       "      <th>EDADSUP</th>\n",
       "      <th>AVGINF</th>\n",
       "      <th>AVGSUP</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>33.000000</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4576.500000</td>\n",
       "      <td>15.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>86.002945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>40.000000</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4542.900000</td>\n",
       "      <td>26.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93.251213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>41.765904</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4403.877191</td>\n",
       "      <td>27.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>101.077599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>23.620997</td>\n",
       "      <td>3.7</td>\n",
       "      <td>4730.400000</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>83.133133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>36.000000</td>\n",
       "      <td>3.3</td>\n",
       "      <td>4506.500000</td>\n",
       "      <td>20.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>91.182457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          EDAD  AVG_DH   MINUTES_DH  EXPERIENCIA  GENERO_FEMENINO  \\\n",
       "995  33.000000     3.6  4576.500000         15.1              0.0   \n",
       "996  40.000000     3.4  4542.900000         26.1              0.0   \n",
       "997  41.765904     3.4  4403.877191         27.4              1.0   \n",
       "998  23.620997     3.7  4730.400000          1.1              0.0   \n",
       "999  36.000000     3.3  4506.500000         20.4              0.0   \n",
       "\n",
       "     GENERO_MASCULINO  RESIDENCIA_ARGENTINA  RESIDENCIA_BRAZIL  \\\n",
       "995               1.0                     1                  0   \n",
       "996               1.0                     1                  0   \n",
       "997               0.0                     1                  0   \n",
       "998               1.0                     0                  0   \n",
       "999               0.0                     1                  0   \n",
       "\n",
       "     RESIDENCIA_MEXICO  NV_ESTUDIO_POST_GRADUATE  ...  ESTUDIO_PREV_BUSINESS  \\\n",
       "995                  0                         0  ...                      0   \n",
       "996                  0                         0  ...                      0   \n",
       "997                  0                         0  ...                      0   \n",
       "998                  1                         0  ...                      0   \n",
       "999                  0                         0  ...                      0   \n",
       "\n",
       "     ESTUDIO_PREV_COMMERCIAL  ESTUDIO_PREV_DEVELOPMENT  \\\n",
       "995                        1                         0   \n",
       "996                        1                         0   \n",
       "997                        0                         0   \n",
       "998                        0                         0   \n",
       "999                        0                         0   \n",
       "\n",
       "     ESTUDIO_PREV_ENGINEERING  ESTUDIO_PREV_MARKETING  EDADINF  EDADSUP  \\\n",
       "995                         0                       0        0        0   \n",
       "996                         0                       0        0        0   \n",
       "997                         1                       0        0        0   \n",
       "998                         1                       0        0        0   \n",
       "999                         0                       0        0        0   \n",
       "\n",
       "     AVGINF  AVGSUP      target  \n",
       "995       0       0   86.002945  \n",
       "996       0       0   93.251213  \n",
       "997       0       0  101.077599  \n",
       "998       0       0   83.133133  \n",
       "999       0       0   91.182457  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = gbreg_final.predict(X_scored)\n",
    "X_scored['target'] = y_pred\n",
    "X_scored.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 22)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scored.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ¡Atención!\n",
    "\n",
    "### La columna agregada con los resultados debe llamarse \"target\", de lo contrario, su envío fallará."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Exportar el marco de datos de resultados como un archivo .csv a su proyecto de Watson Studio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_name': 'results.csv',\n",
       " 'message': 'File saved to project storage.',\n",
       " 'bucket_name': 'ultimo-donotdelete-pr-zrfq3fvphc7tzf',\n",
       " 'asset_id': 'c5e0e950-14b4-427c-a154-491209a9f345'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project.save_data(file_name=\"results.csv\", data=X_scored.to_csv(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
